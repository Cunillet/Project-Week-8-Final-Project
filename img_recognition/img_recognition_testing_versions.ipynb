{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, remove\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_folders(path, start=0, end=100):\n",
    "    elems = {}\n",
    "    for file_name in listdir(path):\n",
    "        file_path = join(path, file_name)\n",
    "        if not isfile(file_path):\n",
    "            print(f'... {file_name} ...')\n",
    "            elems[file_name] = read_paths_cv2(file_path, start, end)\n",
    "    return elems\n",
    "\n",
    "def read_paths_cv2(path, start=0, end=100):\n",
    "    new_size = (128, 128)\n",
    "    animals = []\n",
    "    limit = start\n",
    "    for file_name in listdir(path):\n",
    "        file_path = join(path, file_name)\n",
    "        if limit >= end:\n",
    "            break\n",
    "        if not isfile(file_path):\n",
    "            print(f'WARN - ignoring {file_name}')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = img = cv2.imread(file_path)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            gray_resized = cv2.resize(gray, new_size, interpolation=cv2.INTER_AREA)\n",
    "            if any('' in x for x in gray_resized):\n",
    "                print(f'ERROR - {file_path} - empty content')\n",
    "            animals.append(gray_resized)\n",
    "        except:\n",
    "            print(f'ERROR - {file_path}')\n",
    "        limit += 1\n",
    "\n",
    "    return animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start reading imgs....')\n",
    "elems = read_folders('data/img_train/', end=500)\n",
    "print('end reading imgs')\n",
    "print('data transformed!')\n",
    "#cv2.imshow(\"image\", elems[5])\n",
    "#cv2.waitKey()\n",
    "#print(elems[5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dict with animal - number\n",
    "animal_names = {\n",
    "    'butterfly': 0,\n",
    "    'cat': 1,\n",
    "    'chicken': 2,\n",
    "    'cow': 3,\n",
    "    'dog': 4,\n",
    "    'elephant': 5,\n",
    "    'horse': 6,\n",
    "    'sheep': 7,\n",
    "    'spider': 8,\n",
    "    'squirrel': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array with all data to get the train - test\n",
    "full_array = []\n",
    "targets = []\n",
    "for k,v in elems.items():\n",
    "    full_array = full_array + v\n",
    "    targets = targets + ([animal_names[k]] * len(v))\n",
    "\n",
    "full_array = np.asarray(full_array)\n",
    "targets = np.asarray(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# OPTION 2\n",
    "# rebase pixels from 0 - 255 to 0 - 1 vals\n",
    "full_array = []\n",
    "targets = []\n",
    "for k,v in elems.items():\n",
    "    subset = []\n",
    "    for sublist in v:\n",
    "        subset.append(sublist / 255)\n",
    "    full_array = full_array + subset\n",
    "    targets = targets + ([animal_names[k]] * len(v))\n",
    "\n",
    "full_array = np.asarray(full_array)\n",
    "targets = np.asarray(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_array, targets, test_size=0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "# flatten shape\n",
    "# test 1\n",
    "model = keras.Sequential([\n",
    "    Flatten(input_shape=(128, 128)),\n",
    "    Dense(8192, activation='relu'),\n",
    "    Dense(2048, kernel_initializer='lecun_normal', activation='selu'),\n",
    "    Dense(512, kernel_initializer='lecun_normal', activation='selu'),\n",
    "    Dense(128, kernel_initializer='lecun_normal', activation='selu'),\n",
    "    Dense(10, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST 2 --> IGNORING GRAY SCALE AND SEARCH FOR PATTER INSIDE IMG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# FUNCTIONS WITH COLOR\n",
    "\n",
    "def read_folders_color(path, start=0, end=100):\n",
    "    elems = {}\n",
    "    for file_name in listdir(path):\n",
    "        file_path = join(path, file_name)\n",
    "        if not isfile(file_path):\n",
    "            print(f'... {file_name} ...')\n",
    "            elems[file_name] = read_paths_cv2_color(file_path, start, end)\n",
    "    return elems\n",
    "\n",
    "def read_paths_cv2_color(path, start=0, end=100):\n",
    "    new_size = (128, 128)\n",
    "    animals = []\n",
    "    limit = start\n",
    "    for file_name in listdir(path):\n",
    "        file_path = join(path, file_name)\n",
    "        if limit >= end:\n",
    "            break\n",
    "        if not isfile(file_path):\n",
    "            print(f'WARN - ignoring {file_name}')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = img = cv2.imread(file_path)\n",
    "            img_resized = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "            if any('' in x for x in img_resized):\n",
    "                print(f'ERROR - {file_path} - empty content')\n",
    "            animals.append(img_resized)\n",
    "        except:\n",
    "            print(f'ERROR - {file_path}')\n",
    "        limit += 1\n",
    "\n",
    "    return animals\n",
    "\n",
    "print('start reading imgs....')\n",
    "elems = read_folders_color('data/img/', end=500)\n",
    "print('end reading imgs')\n",
    "print('data transformed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_array, targets, test_size=0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "# Conv2D \n",
    "# test 2\n",
    "model = keras.Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    X_train,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, remove\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import collections\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL VARS\n",
    "img_shape = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folders_color(path, start=0, end=100):\n",
    "    elems = {}\n",
    "    for file_name in listdir(path):\n",
    "        file_path = join(path, file_name)\n",
    "        if not isfile(file_path):\n",
    "            print(f'... {file_name} ...')\n",
    "            elems[file_name] = read_paths_cv2_color(file_path, start, end)\n",
    "    return elems\n",
    "\n",
    "def read_paths_cv2_color(path, start=0, end=100):\n",
    "    animals = []\n",
    "    limit = start\n",
    "    for file_name in listdir(path):\n",
    "        file_path = join(path, file_name)\n",
    "        if limit >= end:\n",
    "            break\n",
    "        if not isfile(file_path):\n",
    "            print(f'WARN - ignoring {file_name}')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = img = cv2.imread(file_path)\n",
    "            img_resized = cv2.resize(img, img_shape, interpolation=cv2.INTER_AREA)\n",
    "            if any('' in x for x in img_resized):\n",
    "                print(f'ERROR - {file_path} - empty content')\n",
    "            animals.append(img_resized)\n",
    "        except:\n",
    "            print(f'ERROR - {file_path}')\n",
    "        limit += 1\n",
    "\n",
    "    return animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "start reading imgs....\n... cat ...\n/Users/Cunillet/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:24: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\nERROR - data/img_train/cat/.DS_Store\n... butterfly ...\nERROR - data/img_train/butterfly/.DS_Store\n... dog ...\nERROR - data/img_train/dog/.DS_Store\n... sheep ...\nERROR - data/img_train/sheep/.DS_Store\n... spider ...\nERROR - data/img_train/spider/.DS_Store\n... chicken ...\nERROR - data/img_train/chicken/.DS_Store\n... horse ...\nERROR - data/img_train/horse/.DS_Store\n... squirrel ...\nERROR - data/img_train/squirrel/.DS_Store\n... cow ...\nERROR - data/img_train/cow/.DS_Store\n... elephant ...\nERROR - data/img_train/elephant/.DS_Store\nend reading imgs\ndata transformed!\n"
    }
   ],
   "source": [
    "print('start reading imgs....')\n",
    "elems = read_folders_color('data/img_train/', end=1000)\n",
    "print('end reading imgs')\n",
    "print('data transformed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dict with animal - number\n",
    "animal_names = {\n",
    "    'butterfly': 0,\n",
    "    'cat': 1,\n",
    "    'chicken': 2,\n",
    "    'cow': 3,\n",
    "    'dog': 4,\n",
    "    'elephant': 5,\n",
    "    'horse': 6,\n",
    "    'sheep': 7,\n",
    "    'spider': 8,\n",
    "    'squirrel': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array with all data to get the train - test\n",
    "full_array = []\n",
    "targets = []\n",
    "for k,v in elems.items():\n",
    "    subset = []\n",
    "    for subv in v:\n",
    "        subset.append(subv / 255)\n",
    "    full_array = full_array + subset.copy()\n",
    "    targets = targets + ([animal_names[k]] * len(v))\n",
    "\n",
    "full_array = np.asarray(full_array)\n",
    "targets = np.asarray(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_array, targets, test_size=0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(img_shape[0], img_shape[1], 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 7992 samples\nEpoch 1/6\n7992/7992 [==============================] - 76s 10ms/sample - loss: 2.0373 - accuracy: 0.2589\nEpoch 2/6\n7992/7992 [==============================] - 70s 9ms/sample - loss: 1.5440 - accuracy: 0.4633\nEpoch 3/6\n7992/7992 [==============================] - 64s 8ms/sample - loss: 1.1552 - accuracy: 0.6021\nEpoch 4/6\n7992/7992 [==============================] - 65s 8ms/sample - loss: 0.8018 - accuracy: 0.7243\nEpoch 5/6\n7992/7992 [==============================] - 66s 8ms/sample - loss: 0.4398 - accuracy: 0.8541\nEpoch 6/6\n7992/7992 [==============================] - 65s 8ms/sample - loss: 0.1990 - accuracy: 0.9379\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2c28e9d10>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save_weights('data/checkpoints/animals_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "start reading imgs....\nend reading imgs\n/Users/Cunillet/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:24: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\ndata transformed!\n"
    }
   ],
   "source": [
    "##################\n",
    "# STARTING TESTS #\n",
    "##################\n",
    "print('start reading imgs....')\n",
    "test_elems = read_paths_cv2_color('data/img_test/horse', end=10)\n",
    "print('end reading imgs')\n",
    "\n",
    "test_array = []\n",
    "for k,v in elems.items():\n",
    "    subset = []\n",
    "    for subv in v:\n",
    "        subset.append(subv / 255)\n",
    "    test_array = test_array + subset.copy()\n",
    "\n",
    "test_array = np.asarray(test_array)\n",
    "print('data transformed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict_classes(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# OPTION 2\n",
    "# rebase pixels from 0 - 255 to 0 - 1 vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/img_train/'\n",
    "validation_dir = 'data/img_test'\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=10000,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(150, 150),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=1000,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(150, 150),\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "# Conv2D \n",
    "# test 2\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=10000,\n",
    "    epochs=15,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
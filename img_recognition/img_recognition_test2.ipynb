{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, remove\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import collections\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL VARS\n",
    "img_shape = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folders_color(path, start=0, end=100):\n",
    "    elems = {}\n",
    "    for file_name in listdir(path):\n",
    "        file_path = join(path, file_name)\n",
    "        if not isfile(file_path):\n",
    "            print(f'... {file_name} ...')\n",
    "            elems[file_name] = read_paths_cv2_color(file_path, start, end)\n",
    "    return elems\n",
    "\n",
    "def read_paths_cv2_color(path, start=0, end=100):\n",
    "    animals = []\n",
    "    limit = start\n",
    "    for file_name in listdir(path):\n",
    "        file_path = join(path, file_name)\n",
    "        if limit >= end:\n",
    "            break\n",
    "        if not isfile(file_path):\n",
    "            print(f'WARN - ignoring {file_name}')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = img = cv2.imread(file_path)\n",
    "            img_resized = cv2.resize(img, img_shape, interpolation=cv2.INTER_AREA)\n",
    "            if any('' in x for x in img_resized):\n",
    "                print(f'ERROR - {file_path} - empty content')\n",
    "            animals.append(img_resized)\n",
    "        except:\n",
    "            print(f'ERROR - {file_path}')\n",
    "        limit += 1\n",
    "\n",
    "    return animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "start reading imgs....\n... cat ...\n/Users/Cunillet/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:24: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\nERROR - data/img_train/cat/.DS_Store\n... butterfly ...\nERROR - data/img_train/butterfly/.DS_Store\n... dog ...\nERROR - data/img_train/dog/.DS_Store\n... sheep ...\nERROR - data/img_train/sheep/.DS_Store\n... spider ...\nERROR - data/img_train/spider/.DS_Store\n... chicken ...\nERROR - data/img_train/chicken/.DS_Store\n... horse ...\nERROR - data/img_train/horse/.DS_Store\n... squirrel ...\nERROR - data/img_train/squirrel/.DS_Store\n... cow ...\nERROR - data/img_train/cow/.DS_Store\n... elephant ...\nERROR - data/img_train/elephant/.DS_Store\nend reading imgs\ndata transformed!\n"
    }
   ],
   "source": [
    "print('start reading imgs....')\n",
    "elems = read_folders_color('data/img_train/', end=1000)\n",
    "print('end reading imgs')\n",
    "print('data transformed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dict with animal - number\n",
    "animal_names = {\n",
    "    'butterfly': 0,\n",
    "    'cat': 1,\n",
    "    'chicken': 2,\n",
    "    'cow': 3,\n",
    "    'dog': 4,\n",
    "    'elephant': 5,\n",
    "    'horse': 6,\n",
    "    'sheep': 7,\n",
    "    'spider': 8,\n",
    "    'squirrel': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array with all data to get the train - test\n",
    "full_array = []\n",
    "targets = []\n",
    "for k,v in elems.items():\n",
    "    subset = []\n",
    "    for subv in v:\n",
    "        subset.append(subv / 255)\n",
    "    full_array = full_array + subset.copy()\n",
    "    targets = targets + ([animal_names[k]] * len(v))\n",
    "print('transformed to 0..1')\n",
    "full_array = np.asarray(full_array)\n",
    "targets = np.asarray(targets)\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_array, targets, test_size=0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(img_shape[0], img_shape[1], 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x150de0b90>"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train, y_train, epochs=6)\n",
    "model.load_weights('data/checkpoints/animals_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save_weights('data/checkpoints/animals_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "start reading imgs....\n/Users/Cunillet/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:24: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\nend reading imgs\ndata transformed!\n"
    }
   ],
   "source": [
    "##################\n",
    "# STARTING TESTS #\n",
    "##################\n",
    "print('start reading imgs....')\n",
    "test_elems = read_paths_cv2_color('data/img_test/cat', start=100, end=110)\n",
    "print('end reading imgs')\n",
    "\n",
    "test_array = []\n",
    "for elem in test_elems:\n",
    "    test_array.append(elem / 255)\n",
    "\n",
    "test_array = np.asarray(test_array)\n",
    "print('data transformed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "seems to be... 1 with a 100.0%\nseems to be... 1 with a 100.0%\nseems to be... 2 with a 100.0%\nseems to be... 9 with a 100.0%\nseems to be... 7 with a 100.0%\nseems to be... 8 with a 100.0%\nseems to be... 1 with a 100.0%\nseems to be... 1 with a 100.0%\nseems to be... 1 with a 100.0%\nseems to be... 8 with a 100.0%\n"
    }
   ],
   "source": [
    "for pos in range(len(test_array)):\n",
    "    #print(np.asarray(test).shape)\n",
    "    counts = np.bincount(model.predict_classes(np.asarray([test_array[pos]])))\n",
    "    mx = np.argmax(counts)\n",
    "    print(f'seems to be... {mx} with a {counts[mx] / sum(counts) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "seems to be... 1 with a 100.0%\n"
    }
   ],
   "source": [
    "#collections.Counter(model.predict_classes(np.asarray(test_array[0])))\n",
    "counts = np.bincount(model.predict_classes(np.asarray([test_array[7]])))\n",
    "mx = np.argmax(counts)\n",
    "print(f'seems to be... {mx} with a {counts[mx] / sum(counts) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.8948948948948949"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[mx] / sum(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# OPTION 2\n",
    "# rebase pixels from 0 - 255 to 0 - 1 vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/img_train/'\n",
    "validation_dir = 'data/img_test'\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=10000,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(150, 150),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=1000,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(150, 150),\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "# Conv2D \n",
    "# test 2\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=10000,\n",
    "    epochs=15,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}